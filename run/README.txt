====================================
COLMOL - Scripts de Execu√ß√£o Local
====================================

Esta pasta cont√©m scripts para rodar o COLMOL localmente no seu computador.

üìÅ ARQUIVOS DISPON√çVEIS:

1. start.sh (Linux/Mac)
   - Inicia Ollama + Proxy Node.js + Django
   - Uso: bash run/start.sh

2. start.bat (Windows)
   - Inicia Ollama + Proxy Node.js + Django
   - Uso: run\start.bat

3. start-django-only.sh (Linux/Mac)
   - Inicia apenas Django (se Ollama j√° estiver rodando)
   - Uso: bash run/start-django-only.sh

4. start-django-only.bat (Windows)
   - Inicia apenas Django (se Ollama j√° estiver rodando)
   - Uso: run\start-django-only.bat

üìã REQUISITOS:

- Python 3.11+
- Node.js 20+
- Ollama (opcional, para OCR com IA)

üöÄ COMO USAR:

== LINUX/MAC ==
1. Dar permiss√£o de execu√ß√£o:
   chmod +x run/start.sh run/start-django-only.sh

2. Executar:
   bash run/start.sh

== WINDOWS ==
1. Executar (duplo clique ou via CMD):
   run\start.bat

üîß PORTAS UTILIZADAS:

- Django:  http://localhost:5000  (interface principal)
- Proxy:   http://localhost:3000  (proxy Ollama)
- Ollama:  http://localhost:8000  (servidor IA)

‚ö†Ô∏è  IMPORTANTE:

- Se as portas j√° estiverem em uso, os scripts v√£o falhar
- Para parar os servidores: Pressione Ctrl+C
- Ollama demora alguns segundos para iniciar na primeira vez
- O modelo llava:latest (~4.7GB) ser√° baixado automaticamente

üìñ DOCUMENTA√á√ÉO COMPLETA:

Consulte o arquivo replit.md na raiz do projeto para mais detalhes
sobre arquitetura, configura√ß√£o e troubleshooting.

====================================
Suporte: Consulte logs no terminal
====================================
